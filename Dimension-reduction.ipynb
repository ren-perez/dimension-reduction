{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80384dcf",
   "metadata": {},
   "source": [
    "For this analysis I'm going to use the Fashion MNIST data set. \n",
    "\n",
    "The fashion mnist data set is composed of 60,000 small square 28x28 grayscale images of 10 types of clothing items: such as shoes, t-shirts, dress. Each item label is mapped to a 0-9 integer.\n",
    "\n",
    "- 0: T-shirt/top\n",
    "- 1: Trouser\n",
    "- 2: Pullover\n",
    "- 3: Dress\n",
    "- 4: Coat\n",
    "- 5: Sandal\n",
    "- 6: Shirt\n",
    "- 7: Sneaker\n",
    "- 8: Bag\n",
    "- 9: Ankle boot\n",
    "\n",
    "I will apply dimension reduction techniques combined with classification methods to build a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881fa713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('fashion-mnist_train.csv')\n",
    "data.drop_duplicates(inplace=True)\n",
    "X = data.drop('label',axis=1)\n",
    "y = data.label\n",
    "\n",
    "# To make your life easier, let's use only the first 1500 data points.\n",
    "X = X.loc[0:1500,]\n",
    "y = y.loc[0:1500,] \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8197e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d3c1a",
   "metadata": {},
   "source": [
    "This data set is a multi-level data set. Some general rules you should follow:\n",
    "\n",
    "1. Tune the dimension reduction technique\n",
    "2. Tune the model\n",
    "3. Select the hyperparameters based on a hold-out set (either via CV or train/validate/test split)\n",
    "4. Report the accuracy on the test set\n",
    "\n",
    "I will be using kernel PCA, LLE, and Isomap. For each dimension reduction technique, I will perform classification with two classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f08257",
   "metadata": {},
   "source": [
    "#### Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b3058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    kpca__gamma: 0.03\n",
      "    kpca__kernel: linear\n",
      "    kpca__n_components: 2\n",
      "Best CV Score: 0.1147\n",
      "\n",
      "Accuracy on Test Set: 0.0984\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"kpca__n_components\": [2, 10, 25, 50, 100],\n",
    "    \"kpca__gamma\": np.linspace(0.03, 0.05, 5),\n",
    "    \"kpca__kernel\": [\"linear\", \"sigmoid\", \"poly\"],\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"kpca\", KernelPCA()),\n",
    "    (\"dtc\", DecisionTreeClassifier(max_depth=2, max_leaf_nodes=2, ccp_alpha=2))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"Best CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_kpca = KernelPCA(n_components=best_params[\"kpca__n_components\"],\n",
    "                     gamma=best_params[\"kpca__gamma\"],\n",
    "                     kernel=best_params[\"kpca__kernel\"])\n",
    "best_clf = DecisionTreeClassifier(max_depth=2, max_leaf_nodes=2, ccp_alpha=2)\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"kpca\", best_kpca),\n",
    "    (\"dtc\", best_clf)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "530275cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    knn__n_neighbors: 5\n",
      "    kpca__gamma: 0.03\n",
      "    kpca__kernel: linear\n",
      "    kpca__n_components: 50\n",
      "\n",
      "Best CV Score: 0.7511\n",
      "\n",
      "Accuracy on Test Set: 0.8298\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"kpca__n_components\": [2, 10, 25, 50, 100],\n",
    "    \"kpca__kernel\": [\"linear\", \"sigmoid\", \"poly\"],\n",
    "    \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "    \"knn__n_neighbors\": range(2, 10),\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"kpca\", KernelPCA()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_kpca = KernelPCA(n_components=best_params[\"kpca__n_components\"],\n",
    "                     kernel=best_params[\"kpca__kernel\"],\n",
    "                     gamma=best_params[\"kpca__gamma\"])\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_params[\"knn__n_neighbors\"])\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"kpca\", best_kpca),\n",
    "    (\"knn\", best_knn)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17223ee2",
   "metadata": {},
   "source": [
    "#### LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1cc1199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    dtc__max_depth: 2\n",
      "    lle__n_components: 2\n",
      "    lle__n_neighbors: 4\n",
      "\n",
      "Best CV Score: 0.1147\n",
      "\n",
      "Accuracy on Test Set: 0.0984\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"lle__n_components\": [2, 10, 25, 50, 100],\n",
    "    \"lle__n_neighbors\": range(2, 7, 2),\n",
    "    \"dtc__max_depth\": [2, 4, 8, 16]\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"lle\", LocallyLinearEmbedding()),\n",
    "    (\"dtc\", DecisionTreeClassifier(max_leaf_nodes=2, ccp_alpha=2))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_kpca = LocallyLinearEmbedding(n_components=best_params[\"lle__n_components\"],\n",
    "                     n_neighbors=best_params[\"lle__n_neighbors\"])\n",
    "best_clf = DecisionTreeClassifier(max_depth=best_params[\"dtc__max_depth\"], max_leaf_nodes=2, ccp_alpha=2)\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"kpca\", best_kpca),\n",
    "    (\"dtc\", best_clf)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "125cf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    knn__n_neighbors: 7\n",
      "    lle__n_components: 50\n",
      "    lle__n_neighbors: 8\n",
      "\n",
      "Best CV Score: 0.7209\n",
      "\n",
      "Accuracy on Test Set: 0.7739\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"lle__n_components\": [2, 10, 25, 50, 100],\n",
    "    \"lle__n_neighbors\": range(2, 11, 2),\n",
    "    \"knn__n_neighbors\": range(2, 10),\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"lle\", LocallyLinearEmbedding()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_kpca = LocallyLinearEmbedding(n_components=best_params[\"lle__n_components\"],\n",
    "                     n_neighbors=best_params[\"lle__n_neighbors\"])\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_params[\"knn__n_neighbors\"])\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"kpca\", best_kpca),\n",
    "    (\"knn\", best_knn)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516fe7ac",
   "metadata": {},
   "source": [
    "#### Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8441ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    dtc__max_depth: 2\n",
      "    isomap__n_components: 2\n",
      "    isomap__n_neighbors: 2\n",
      "\n",
      "Best CV Score: 0.1147\n",
      "\n",
      "Accuracy on Test Set: 0.0984\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"isomap__n_components\": [2, 10, 25, 50, 100],\n",
    "    \"isomap__n_neighbors\": range(2, 11, 2),\n",
    "    \"dtc__max_depth\": [2, 4, 8, 16]\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"isomap\", Isomap()),\n",
    "    (\"dtc\", DecisionTreeClassifier(max_leaf_nodes=2, ccp_alpha=2))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_kpca = Isomap(n_components=best_params[\"isomap__n_components\"],\n",
    "                     n_neighbors=best_params[\"isomap__n_neighbors\"])\n",
    "best_clf = DecisionTreeClassifier(max_depth=best_params[\"dtc__max_depth\"], max_leaf_nodes=2, ccp_alpha=2)\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"kpca\", best_kpca),\n",
    "    (\"dtc\", best_clf)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63cb3d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    isomap__n_components: 25\n",
      "    isomap__n_neighbors: 4\n",
      "    knn__n_neighbors: 7\n",
      "\n",
      "Best CV Score: 0.7129\n",
      "\n",
      "Accuracy on Test Set: 0.8059\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"isomap__n_components\": [2, 10, 25, 50, 100],\n",
    "    \"isomap__n_neighbors\": range(2, 11, 2),\n",
    "    \"knn__n_neighbors\": range(2, 10),\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"isomap\", Isomap()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_kpca = Isomap(n_components=best_params[\"isomap__n_components\"],\n",
    "                     n_neighbors=best_params[\"isomap__n_neighbors\"])\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_params[\"knn__n_neighbors\"])\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"kpca\", best_kpca),\n",
    "    (\"knn\", best_knn)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b036ba",
   "metadata": {},
   "source": [
    "#### What is the best combination according to your accuracy score on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d0712",
   "metadata": {},
   "source": [
    "A summary of the results is presented in the following table:\n",
    "| Dimension Reduction | Classifier    | Accuracy Score |\n",
    "| ------------------- | ------------- | -------------- |\n",
    "| KPCA                | Decision Tree | 0.0984         |\n",
    "| **KPCA**            | **KNN**       | **0.8298**     |\n",
    "| LLE                 | Decision Tree | 0.0984         |\n",
    "| LLE                 | KNN           | 0.7739         |\n",
    "| Isomap              | Decision Tree | 0.0984         |\n",
    "| Isomap              | KNN           | 0.8059         |\n",
    "\n",
    "The best combination appears to be KPCA with KNN, which achieved an accuracy score of 0.8298 on the test set. \n",
    "\n",
    "KPCA sseems to be effective in preserving important information about the dataset. My understanding is that this is achieved by projecting it into a higher-dimensional space using the linear kernel function.\n",
    "\n",
    "KNN can work well when the dimensionality of the data is reduced effectively because it relies on distance metrics to make predictions. Dimensionality reduction techniques like KPCA can help in finding meaningful representations of data points in lower dimensions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99acc65e",
   "metadata": {},
   "source": [
    "Now using the original data set (i.e. not reduced data) and the two classifers, I'll run the procedure again, but this time without any dimension reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b532802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    dtc__ccp_alpha: 0.0\n",
      "    dtc__max_depth: 4\n",
      "    dtc__max_leaf_nodes: 7\n",
      "\n",
      "Best CV Score: 0.5378\n",
      "\n",
      "Accuracy on Test Set: 0.5878\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"dtc__max_depth\": range(2, 8),\n",
    "    \"dtc__max_leaf_nodes\": range(2, 8),\n",
    "    \"dtc__ccp_alpha\": np.linspace(0, 10, 5)\n",
    "}\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"dtc\", DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_dtc = DecisionTreeClassifier(max_depth=best_params[\"dtc__max_depth\"],\n",
    "                     max_leaf_nodes=best_params[\"dtc__max_leaf_nodes\"],\n",
    "                     ccp_alpha=best_params[\"dtc__ccp_alpha\"])\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"dtc\", best_dtc)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e04cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Train Set):\n",
      "    knn__n_neighbors: 6\n",
      "    knn__p: 1\n",
      "    knn__weights: distance\n",
      "\n",
      "Best CV Score: 0.7502\n",
      "\n",
      "Accuracy on Test Set: 0.8298\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": range(2, 10),\n",
    "    \"knn__weights\": ['uniform', 'distance'],\n",
    "    \"knn__p\": [1, 2],\n",
    "}\n",
    "\n",
    "knn = Pipeline([\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters (Train Set):\")\n",
    "for param in grid_search.best_params_:\n",
    "    print(f\"    {param}: {grid_search.best_params_[param]}\")\n",
    "print(f\"\\nBest CV Score: {round(grid_search.best_score_, 4)}\")\n",
    "\n",
    "# TEST\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_params[\"knn__n_neighbors\"],\n",
    "                                weights=best_params[\"knn__weights\"],\n",
    "                                p=best_params[\"knn__p\"])\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    (\"knn\", best_knn)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on Test Set: {round(accuracy, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28555acc",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "Accuracy Scores for Classifiers without Dimension Reduction:\n",
    "* Decision Tree: 0.7502\n",
    "* KNN: 0.8298\n",
    "\n",
    "The accuracy score for KNN in this part (0.8298) is identical to the accuracy score achieved when KNN was used with KPCA in the first part (0.8298). This suggests that, for this specific dataset, the dimension reduction technique (KPCA) didn't significantly improve or degrade the performance of KNN.\n",
    "\n",
    "The accuracy score for the Decision Tree in this part (0.7502) is also consistent with the results obtained when dimension reduction techniques were used in the first part (0.0984). Decision Trees tend to be less effective in high-dimensional spaces, whether dimensionality reduction is applied or not, and KNN seems to be a more suitable choice for this dataset.\n",
    "\n",
    "In summary, in this specific scenario and dataset, KNN consistently performs better than Decision Trees in terms of accuracy, both with and without dimension reduction techniques. The dimensionality reduction techniques applied in the first part did not seem to provide a significant advantage in this case, and KNN alone achieved the highest accuracy score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
